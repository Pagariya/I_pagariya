In this exercise I implemented simple neural network with numpy. The tasks will be:


PART 1:
In this part I created different function for neural network under class TwoLayerNet

Implementing a Forward propagation
Completing the Forward propagation by computing the loss
Implementing a Back propagation
Training the neural network

PART 2:

Testing the code by intailizing parameters and calling functions for Neural network written in PART 1 



#---------PART 1-------------
# --------Neural Network Classifier

import numpy as np
import time

class TwoLayerNet(object):

    def __init__(self, input_dim, hidden_dim, output_dim, std=1e-4):
       
        self.params = {}
        self.params['W1'] = std * np.random.randn(input_dim, hidden_dim)
        self.params['b1'] = np.zeros(hidden_dim)
        self.params['W2'] = std * np.random.randn(hidden_dim, output_dim)
        self.params['b2'] = np.zeros(output_dim)
        
    def loss_grad(self, X, y=None, reg=0.0):
        
        # ------------Unpack variables from the params dictionary
    
        W1 = self.params['W1']
        b1 = self.params['b1']
        W2 = self.params['W2'] 
        b2 = self.params['b2']
        N, D = X.shape
       
        #--------------------------------------- forward propagation --------------------------------------- 
        
        scores = None
        z2 = np.dot(X, W1) + b1
        a2 = np.maximum(0, z2)
        scores = np.dot(a2, W2) + b2
        
        return scores
        #--------------------------------------- loss function ---------------------------------------------

        loss = None
        
        # Compute the loss with softmax and store it in the variable loss. Include L2 regularization for W1 and W2.
        # Make sure to handle numerical instabilities.
        
        # Softmax 
        exp_scores = np.exp(scores - np.amax(scores)) 
        probs = exp_scores / np.sum(exp_scores, axis = 1, keepdims = True)
        
        # Cross entropy loss
        log_probs = -np.log(probs[range(N), y])
        cross_entropy_loss = np.sum(log_probs) / N
        
        # Regularization
        regularizer = ((reg * np.sum(np.square(W1))) + (reg * np.sum(np.square(W2))))
        
        # Loss function
        loss = cross_entropy_loss + regularizer
        
        #--------------------------------------- back propagation -------------------------------------------
        
        grads = {}  
        
        # --------Compute the derivatives of the weights and biases (back propagation).
        # --------Store the results in the grads dictionary, where 'W1' referes to the gradient of W1 etc.
        
        def reluDerivative(r):
            r[r<=0] = 0
            r[r>0] = 1
            return r
        
        dw_scores = probs
        dw_scores[range(N), y] -= 1
        dw_scores = dw_scores / N
        
        # dLoss/dW2
        dW_2 = np.dot(a2.T, dw_scores) + (2 * reg * W2)
        
        # dLoss/db2
        db_2 = np.sum(dw_scores, axis = 0, keepdims = True)
        
        # dLoss/dW1
        dW_1 = np.dot(X.T, (np.dot(dw_scores, W2.T)) * reluDerivative(a2)) + (2 * reg * W1)
        
        # dLoss/db1
        db_1 = np.sum(np.dot(dw_scores, W2.T) * reluDerivative(a2), axis = 0, keepdims = True)

        grads.update({"W1": dW_1, "W2": dW_2, "b1": db_1, "b2": db_2})
        return loss, grads

    
    def train(self, X, y, X_val, y_val,
          learning_rate=1e-3, learning_rate_decay=0.95,
          reg=5e-6, num_iters=100,
          batch_size=200, verbose=False):

        num_train = X.shape[0]
        iterations_per_epoch = max(num_train / batch_size, 1)

    # ---------------Use SGD to optimize the parameters in self.model
        loss_history = []
        train_acc_history = []
        val_acc_history = []

        for it in range(num_iters):
            X_batch = None
            y_batch = None
                
 
        
        #-------------- Created a random minibatch of training data X and labels y, and stor
        #-------------- them in X_batch and y_batch.
            
            minis = []

            np.random.seed(0)
            num_train = X.shape[0]
            rand_indices = np.random.choice(np.arange(num_train), size = 1000, replace = True)
            X_b = X[rand_indices, :]
            y_b = y[rand_indices]
            n_minibatches = X_b.shape[0] // batch_size

            i = 0

            for i in range(n_minibatches):
                mini_X = X_b[i * batch_size:(i + 1)*batch_size, :]
                mini_y = y_b[i * batch_size:(i + 1)*batch_size]

                X_bat = mini_X[:, :]
                y_bat = mini_y[:]
                minis.append((X_bat, y_bat))
                
            mini_batch = minis 
                           
            for mini in mini_batch:
                
                X_batch, y_batch = mini
                
                # Compute the Loss & Gradients of current minibatch
            
                loss, grads = self.loss_grad(X_batch, y=y_batch, reg=reg)
                loss_history.append(loss)
                
            
      
            
            #--------- Updated the parameters of the network (in self.params) by using stochastic gradient descent. 

                self.params['W1'] = self.params['W1'] - (learning_rate * grads["W1"])
                self.params['W2'] = self.params['W2'] - (learning_rate * grads["W2"])
                self.params['b1'] = self.params['b1'] - (learning_rate * grads["b1"])
                self.params['b2'] = self.params['b2'] - (learning_rate * grads["b2"])

                # Decay learning rate
                learning_rate *= learning_rate_decay

            if verbose and it % 10 == 0:
                print('iteration %sd / %d: loss %f' % (it, num_iters, loss))

            # Every epoch, check train and val accuracy and decay learning rate.
            if it % iterations_per_epoch == 0:
                
                # Check accuracy
                train_acc = (self.predict(X_batch) == y_batch).mean()
                val_acc = (self.predict(X_val) == y_val).mean()
                train_acc_history.append(train_acc)
                val_acc_history.append(val_acc)

        
        return {

            'loss_history': loss_history,
            'train_acc_history': train_acc_history,
            'val_acc_history': val_acc_history

        }
    
    
    #-----------------------------------------function to predict the y for given x
    
    
    def predict(self, X):
    
        y_pred = None
    
        
        W1 = self.params['W1']
        b1 = self.params['b1']
        W2 = self.params['W2'] 
        b2 = self.params['b2']
        
        a2 = np.maximum(0, np.dot(X, W1) + b1)
        scores = np.dot(a2, W2) + b2
        y_pred = np.argmax(scores, axis = 1)
        
        return y_pred
        
        
        
#-----------------PART 2------------- :        


# The input data (X) with the associated labels (y) as well as the weights and biases 
# are initialized with random numbers. A seed is set to make your results comparable.

import numpy as np
import matplotlib.pyplot as plt

input_dim = 4
hidden_dim = 10
num_classes = 3
num_inputs = 5

def init_net():
    np.random.seed(0)
    return TwoLayerNet(input_dim, hidden_dim, num_classes, std=1e-1)

def init_data():
    np.random.seed(1)
    X = 10 * np.random.randn(num_inputs, input_dim)
    y = np.array([0, 1, 2, 2, 1])
    return X, y

def rel_error(x, y):
    """ returns relative error """
    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))

%matplotlib inline
plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots
plt.rcParams['image.interpolation'] = 'nearest'
plt.rcParams['image.cmap'] = 'gray'

net = init_net()
X, y = init_data()


Forwardpass loss

loss, _= net.loss_grad(X, y, reg=0.05)
correct_loss = 1.30378789133
print(loss)


#------------------------------------------Training a network---------------------------------------------*

Finaly we want to train our network.

net = init_net()
stats = net.train(X, y, X, y,
            learning_rate=1e-1, reg=5e-6,
            num_iters=100, verbose=True)

print('Final training loss: ', stats['loss_history'][-1])

# plot the loss history
plt.plot(stats['loss_history'])
plt.xlabel('iteration')
plt.ylabel('training loss')
plt.title('Training Loss history')
plt.show()



iteration 0d / 100: loss 0.437614
iteration 10d / 100: loss 0.016142
iteration 20d / 100: loss 0.014579
iteration 30d / 100: loss 0.014469
iteration 40d / 100: loss 0.014461
iteration 50d / 100: loss 0.014460
iteration 60d / 100: loss 0.014460
iteration 70d / 100: loss 0.014460
iteration 80d / 100: loss 0.014460
iteration 90d / 100: loss 0.014460
Final training loss:  0.014460416251124625


In the above plot, we can observe that the loss reaches a steady value after roughly 20 iterations, the loss reaches a steady value.
